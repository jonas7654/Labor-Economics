---
title: "PS2 Labor Economics [2020]"                      
subtitle: "R Version"
author: "Jonas Veit [jveit@mail.uni-mannheim.de]"
output: 
  html_document:
    toc: true
    toc_depth: 1
    number_sections: false


---
\
\
\
\

# Estimating the intensive margin labor supply elasticity

\
\
\
Load helpful packages and the cps dataset
```{r setup, include=TRUE, message=FALSE}
library(tidyverse)
library(haven)
library(ggthemes)
library(dummies)
library(gridExtra)



cps = read_dta(file = '~/Documents/Programming/R/Labor Economics [2020]/Data for PS2/cps-1984-2010.dta')

```
\
\
\

### $a)$
```{r}
summary(cps)
```

```{r,message=FALSE}
mean(cps$nKids)
mean(cps$hisp)
```
The average number of childen is $0.653$

The share of hispanic women in this data is $15.5$%
\
\
\

### $b)$
```{r , message=FALSE}
hourly_wage = cps$incwage / (52*cps$uhrswork)

mean(hourly_wage,na.rm = TRUE)
sd(hourly_wage,na.rm = TRUE)
```
Since there are NaN's in our hourly wage vector we have to use **na.rm = TRUE**
\
\
$mean(hourly\_wage) = 10.091$
\
\
$sd(houry\_wage) = 13.277$
\
\
There are missing values because the column $uhrswork$ contains zero rows.
\
Dividing by zero produces NaN's. You can calculate the amount of zeros by executing the following command.
```{r}
sum(cps$uhrswork == 0)
```
Compare it with the number of NaN's in the $hourly\_wage$ vector.
```{r}
sum(hourly_wage == 'NaN')
```
\
\
\

### $c)$
```{r}
mean(cps$emp_ind)
mean(cps$emp_ind[cps$nKids == 0])
mean(cps$emp_ind[cps$nKids == 1])
mean(cps$emp_ind[cps$nKids == 2])


```
The overall rate of labor force participation is $74.41$%
\
\
The rate of labor force participation among women who have no children is $78.59$%
\
\
The rate for 1 children is $71.78$%
\
\
The rate for 2 children is $67.74$
\
\
The rate of labor force participation among women with 10 children is very high because of the amount of women who have 10 children.
```{r}
cps %>% 
  filter(nKids == 10) %>%
  select(emp_ind)

```
we can clearly see that there are just 10 women with 10 children in this dataset and 6 of them are participating in the labor force i.e $60$%
\
\
\

### $d)$
\

we want to estimate the model $$\textrm{uhrswork}_i = \beta_0 + \beta_1 \textrm{wage}_i + \varepsilon_i$$
```{r}
regression1 = lm(cps$uhrswork ~ hourly_wage);regression1
sum_reg1 = summary(regression1);summary(regression1)[4]
```
The estimate for $\hat{\beta}_1$ is $0.06117$
\
\
The standard error for $\hat{\beta}_1$ is $0.00148$ and the t-statistic is $41.20$
\
We can see that $Pr(>|t|)$ is $0$ that means our p value is 0
\
\
According to the estimated $\hat{\beta}_1$ an one dollar increase in wage should result in an increase of hours worked of 0.0611
\
\
Now estimate the elasticity of hours worked with respect to wage
```{r}
avg_hourly_wage = mean(hourly_wage,na.rm = TRUE)

avg_uhrswork = mean(cps$uhrswork)

regression1$coefficients[2]*(avg_hourly_wage/avg_uhrswork)
```

The estimated elasticity $e$ is equal to $0.0199 \approx 0.02$
\
\
\

### $e)$
\
Now we want to estimate the log regression $$\log(\textrm{uhrswork}_i) = \beta_0 + \beta_1 \log(\textrm{wage}_i) + \varepsilon_i$$
```{r}
log_uhrswork = log(cps$uhrswork)
log_wage = log(hourly_wage)
log_regression1 = lm(log_uhrswork ~ log_wage);log_regression1
sum_logreg1 = summary(log_regression1);sum_logreg1[4]
```
The estimate for $\hat{\beta}_1$ is $0.08245$
\
\
The standard error for $\hat{\beta}_1$ is $0.00069$ and the t-statistic is $119.2211$
\
We can see that $Pr(>|t|)$ is $0$ that means our p value is 0
\
\
$e_{reg1} = 0.01992475$ \ vs. \ $e_{log(reg1)} = 0.08245$
\
\
If the wage increases by $10\%$ hours worked would increase by $10 \times 0.08245\ = 0.8245\%$
\
\
\

### $f)$
\
I am combining $log\_wage$ and $age$ into one dataframe for easier usage.
\
$log\_hours$ contains NaN's that means that we have to use the command: **use = 'complete.obs'**
```{r}
cov_dataframe = data.frame(log_wage,cps$age)
cov(cov_dataframe,use = 'complete.obs')
0.0053*(cov(log_wage,cps$age,use = 'complete.obs')/var(log_wage,na.rm = TRUE))
```
\
$$OVB = \beta_{age} \frac{Cov(log\_wage,age)}{\tilde{S}^2_{log\_wage}} = 0.0053 \frac{2.219}{0.997} = 0.012$$
\
We estimate the OVB to be around 0.012 i.e a elasticity change of 0.012
\
\
\

### $g)$
\
$$\hat{\beta} = \beta + \beta_{age} \frac{Cov(log\_wage,age)}{\tilde{S}^2_{log\_wage}} \Leftrightarrow \beta = \hat{\beta} -  \beta_{age} \frac{Cov(age,log\_wage)}{\tilde{S}^2_{log\_wage}} = 0.08245 - 0.012 = 0.07045$$
\
\
\

### $h)$
\
We want to estimate the model
\
$$\log(\textrm{uhrswork}_i) = \beta_0 + \beta_1 \log(\textrm{wage}_i) +\beta_2\textrm{edu_years} + \beta_3\textrm{age} + \beta_4 \textrm{age}^2 + \beta_5 \textrm{year} + \beta_6 \textrm{hisp} + \varepsilon_i$$
```{r}
age_squared = cps$age^2
log_regression2 = lm(data = cps,formula = log_uhrswork ~ log_wage + edu_yrs + age + age_squared + year + hisp);log_regression2
```
\
The estimated labor supply elasticity does not stay the same. We are now controlling for other variables. Therefore we are able to adress the omitted variable bias.
\
\
\

### $i)$
\
Here we create a new DataFrame with all women with no childen which we access in the $lm()$ command.
\
*** Moreover we create new vectors for $\log(wage)$ , $\log(uhrswork)$ and $\textrm{age}^2$ conditioned on $nKids == 0$
\
Note that I used a different approach to create the DataFrame and vectors using the package 'dplyr' which belongs to the 'tidyverse' package that we loaded at the beginning
\
\
We could have also used the following base-R commands:
\
$$\textrm{cps_nochildren = cps \$ [cps \$ nKids == 0,]}$$
\
\
$$\textrm{log_wage_nochildren} = \log(\textrm{cps_nochildren \$ incwage / (52*cps_nochildren \$ uhrswork}))$$
\
$$...$$
\
\
But using 'dplyr' makes the code much easier to read!
\
```{r}
cps_nochildren = cps %>%
  filter(nKids == 0)

log_wage_nochildren = cps %>%
  filter(nKids == 0) %>%
  select(incwage,uhrswork) %>%
  transmute(log(incwage/(52*uhrswork))) %>%
  pull()


log_uhrswork_nochildren = cps %>%
  filter(nKids == 0) %>%
  select(uhrswork) %>%
  transmute(log(uhrswork)) %>%
  pull()

age_squared_nochildren = cps_nochildren %>%
  select(age) %>%
  transmute(age^2) %>%
  pull()

```


```{r}
log_regression_nochildren = lm(data = cps_nochildren,formula = log_uhrswork_nochildren ~ log_wage_nochildren + edu_yrs + age + age_squared_nochildren + year + hisp);log_regression_nochildren
```
\
```{r}
cps_children = cps %>%
  filter(nKids > 1)

log_wage_children = cps %>%
  filter(nKids > 1) %>%
  select(incwage,uhrswork) %>%
  transmute(log(incwage/(52*uhrswork))) %>%
  pull()


log_uhrswork_children = cps %>%
  filter(nKids > 1) %>%
  select(uhrswork) %>%
  transmute(log(uhrswork)) %>%
  pull()

age_squared_children = cps_children %>%
  select(age) %>%
  transmute(age^2) %>%
  pull()
```

```{r}
log_regression_children = lm(data = cps_children,formula = log_uhrswork_children ~ log_wage_children + edu_yrs + age + age_squared_children + year + hisp);log_regression_children
```
\
\
\

### $j)$
\
```{r}

```
\
\
\
\
\

# Minimum Wage Application
\
\
\
Load the corresponding dataset.
```{r}
dubelesterreich_minwage = read_dta(file = "~/Documents/Programming/R/Labor Economics [2020]/Data for PS2/dubelesterreich_minwage.dta")

dubelesterreich_empdata = read_dta(file = "~/Documents/Programming/R/Labor Economics [2020]/Data for PS2/dubelesterreich_empdata.dta")

dubelesterreich_empdata_contig_minwage = read_dta(file = "~/Documents/Programming/R/Labor Economics [2020]/Data for PS2/dubelesterreich_empdata_contig_minwage.dta")
```
\
\
\

### $1)$ Prepare the dataset

\
Create the meanwage vector and append it to the dataframe.
\
```{r}
minwage = rep(0,length(dubelesterreich_minwage$st_mw))

for (i in 1:length(t(minwage))){
  if (is.na(dubelesterreich_minwage$st_mw[i] == TRUE)){
    minwage[i] = dubelesterreich_minwage$fed_mw[i] 
  } else if (dubelesterreich_minwage$st_mw[i] > dubelesterreich_minwage$fed_mw[i]){
    minwage[i] = dubelesterreich_minwage$st_mw[i]
  } else if (dubelesterreich_minwage$st_mw[i] == dubelesterreich_minwage$fed_mw[i]){
    minwage[i] = dubelesterreich_minwage$st_mw[i]
  } else {
    minwage[i] = dubelesterreich_minwage$fed_mw[i]
  }
}

minwage_clean = dubelesterreich_minwage %>%
  add_column(minwage)
```
\
```{r}
summary(dubelesterreich_minwage$st_mw)
summary(dubelesterreich_minwage$fed_mw)
summary(minwage_clean)
```


\

### $a)  \  \ \ \textrm{&} \ \ \ b)$

\
$\min = 3.350$
\
$\max = 7.930$
\
\
\
Save the minwage vector as a file.
```{r}
write_dta(as.data.frame(minwage_clean),path = "~/Documents/Programming/R/Labor Economics [2020]/minwage_clean.dta")
```
\
\

### $c)$

\
```{r}


mean_minwage = minwage_clean %>%
  group_by(year) %>%
  arrange(year) %>%
  summarise(mean = mean(minwage))

mean_fedwage = minwage_clean %>%
  group_by(year) %>%
  arrange(year) %>%
  summarise(mean_fed = mean(fed_mw))

mean_minwage_fed = data.frame(mean_fedwage,mean_minwage) %>%
  select(-year.1) %>%
  pivot_longer(cols = c("mean_fed","mean"));colnames(mean_minwage_fed)[3] = "means"

mean_minwage_plot = ggplot(mean_minwage) +
  geom_path(aes(x = year , y = mean),color = "dodgerblue4") +
  scale_x_continuous(breaks = scales::pretty_breaks(n = 5)) +
  ggtitle(label = "Average minimum wage by year") +
  ylab("") +
  xlab("Year") +
  theme_stata()

mean_fed_minwage_plot = ggplot(mean_minwage_fed,aes(color = name)) +
  geom_path(aes(x = year , y = means)) +
  scale_x_continuous(breaks = scales::pretty_breaks(n = 5)) +
  ylab(label ="") +
  xlab(label = "Year") +
  ggtitle(label = "Average minimum wage and federal minimum wage by year") +
  scale_color_manual(name="",labels=c("Average minimum wage","Federal minimum wage"),values=c("dodgerblue4","red")) +
  theme_stata()
```
\
```{r , multi.col=TRUE}
mean_minwage_plot


mean_fed_minwage_plot
```
\
\
\

### $d)$

\
Filter for year == 2000
\
```{r}
dubelesterreich_empdata_2000 = dubelesterreich_empdata %>%
  filter(year == 2000)


mean_emp_rest = dubelesterreich_empdata_2000 %>%
  group_by(state) %>%
  arrange(state) %>%
  summarise(mean_emp_rest = mean(emp_rest))

mean_emp_tot = dubelesterreich_empdata_2000 %>%
  group_by(state) %>%
  arrange(state) %>%
  summarise(mean_emp_tot = mean(emp_tot))

mean_emp_totemp = data.frame(mean_emp_rest,mean_emp_tot) %>%
  select(-c("state","state.1"))

mean_emp_totemp_plot = ggplot(mean_emp_totemp) +
  geom_point(aes(x = mean_emp_tot , y = mean_emp_rest),color = "dodgerblue4") +
  scale_x_continuous(breaks = scales::breaks_pretty(n = 5)) +
  theme_stata()

mean_emp_totemp_plot
```
\
\
```{r}
logmean_emp_rest = dubelesterreich_empdata_2000 %>%
  group_by(state) %>%
  arrange(state) %>%
  summarise(logmean_emp_rest = mean(logemp_rest))

logmean_emp_tot = dubelesterreich_empdata_2000 %>%
  group_by(state) %>%
  arrange(state) %>%
  summarise(logmean_emp_tot = mean(logemp_tot))

logmean_emp_totemp = data.frame(logmean_emp_rest,logmean_emp_tot) %>%
  select(-c("state","state.1"))

logmean_emp_totemp_plot = ggplot(logmean_emp_totemp) +
  geom_point(aes(x = logmean_emp_tot , y = logmean_emp_rest),color = "dodgerblue4") +
  scale_x_continuous(breaks = scales::breaks_pretty(n = 5)) +
  theme_stata()

logmean_emp_totemp_plot
```
\
\
\

### $e)$

\
```{r}
regression1 = lm(data = dubelesterreich_empdata , formula = emp_rest ~ emp_tot);summary(regression1)

regression2 = lm(data = dubelesterreich_empdata , formula = logemp_rest ~ logemp_tot);summary(regression2)
```
\
Regression 1:
\
for each additional job in a county there are about 0.059 additional restaurants
\
with a t-value of $1415.29$ the coefficient is statistically significant
\
\
Regression 2:
\
If employment goes up by one percent restaurant employment goes up by $\approx 1$ percent 
\
\
\

### $f)$
\

```{r}
minwage_clean = minwage_clean %>%
  select(state,period,minwage)
  
dubelesterreich_empdata = merge(dubelesterreich_empdata,minwage_clean,by = c("state","period"))


dubelesterreich_empdata_minwage = dubelesterreich_empdata %>%
  mutate(minwage = replace(minwage,year == 2004 & county == 6075,8.5)) %>%
  mutate(minwage = replace(minwage,year == 2005 & county == 6075,8.62)) %>%
  mutate(minwage = replace(minwage,year == 2006 & county == 6075, 8.82)) %>%
  mutate(logminwage = log(minwage))

write_dta(dubelesterreich_empdata , path = "~/Documents/Programming/R/Labor Economics [2020]/dubelesterreich_empdata_minwage.dta")
```

\
\
\

# Estimating the Effect of Minimum Wages
\
\
\
\

### $a)$
\
\
Equation $(1)$ in the Dube, Lester and Reich article is the following
\
\
$$\ln_{it} = \alpha + \eta\ln(MW_{it}) + \delta\ln(y_{it})^{TOT} + \gamma\ln(pop_{it}) + \phi_i + \tau_t + \varepsilon_{it}$$
\
\
\
First we want to estimate
\
\

$$\log(\textrm{earnings_rest}) = \alpha + \eta\log(\textrm{minwage}) + \delta\log(\textrm{earnings_tot}) + \varepsilon_{it}$$
\
```{r}
log_regression1 = lm(data = dubelesterreich_empdata_minwage, formula = logearnings_rest ~ logminwage + logearnings_tot);log_regression1

summary(log_regression1)[4]
```
\
$\hat{\eta} = 0.5460$
\
\
The coefficient is statistically significant with a t-value of $94.46$ and a p-value of $0$
\
\
\

### $b)$
\
\
Since there is a multicollinearity issue within the period columns R will omitt one of the variables so that $(\mathrm{X'X})^{-1}$ is invertible.
\
In the Solution STATA omitted the variable 'period64'. To recreate the same coefficients I have also removed the variable 'period64' from the dummy dataframe.
\
```{r}
dummy_dataframe_period = as.data.frame(dummy(dubelesterreich_empdata_minwage$period));colnames(dummy_dataframe_period) = paste("period" , 1:66 , sep = "")

dummy_regression1 = lm(data = select(dummy_dataframe_period,-period64),formula = dubelesterreich_empdata_minwage$logearnings_rest ~ dubelesterreich_empdata_minwage$logminwage + dubelesterreich_empdata_minwage$logearnings_tot + .);dummy_regression1$coefficients[c(2,3)]
```
\
\
\
Now we want to include the county fixed effects.
\
Note that we could use the same procedure as before. This would take relatively long to compute and is memory heavy.
\
The corresponding code would be :
\
\

$$\textrm{dummy_dataframe_county = as.data.frame(dummy(dubelesterreich_empdata_minwage\$county))}$$
\
$$\textrm{dummy_dataframe_county_period = data.frame(dummy_dataframe_period , dummy_dataframe_county)
}$$
\
$$\textrm{dummy_reg_county_period = lm(data = dummy_dataframe_county_period , formula =}$$
$$\textrm{dubelesterreich_empdata_minwage\$logearnings_rest ~ dubelesterreich_empdata_minwage\$logminwage +}$$
$$\textrm{dubelesterreich_empdata_minwage\$logearnings_tot + .)}$$
\
\
Using the package $plm$ makes this computation much faster and easier-
```{r}
library(plm)

dummy_regression_period_county = plm(logearnings_rest ~ logminwage + logearnings_tot + dummy(period) , data=dubelesterreich_empdata_minwage, model="with" , index = "county")

dummy_regression_period_county$coefficients[c(1,2)]

```



\
\
\

### Unemployment Insurance Extension
\
\
\
Load the dataset
\
```{r}
UI_RD = read_dta(file = "~/Documents/Programming/R/Labor Economics [2020]/Data for PS2/UI_RD.dta")
```
\
\
# Descriptive Analysis
\
$a)$
\
```{r}
summary(UI_RD)
```
\
\
$b)$
\
```{r , fig.align="center"}
ui_p_mean_per_age = UI_RD %>%
  group_by(age) %>%
  summarise(mean_P = mean(P))

ui_p_mean_per_age_plot = ggplot(data = ui_p_mean_per_age) +
  geom_line(aes(x = age , y = mean_P ),color = "dodgerblue4") +
  xlab("Age") +
  ylab("Potential UI Duration") +
  ggtitle(label = "Potential UI Duration by Age") +
  scale_y_continuous(breaks = scales::breaks_pretty(n = 5)) +
  theme_stata()

ui_p_mean_per_age_plot

```
\
\
$c)$
\
```{r , fig.align="center"}
ui_p_mean_per_age_exp52 = UI_RD %>%
  filter(expbaseline >= 52) %>%
  group_by(age) %>%
  summarise(mean_P = mean(P))

ui_p_mean_per_age_exp52_plot = ggplot(data = ui_p_mean_per_age_exp52) +
  geom_line(aes(x = age , y = mean_P ),color = "dodgerblue4") +
  xlab("Age") +
  ylab("Potential UI Duration") +
  ggtitle(label = "Potential UI Duration by Age") +
  scale_y_continuous(breaks = c(10,15,20,25),limits = c(10,26)) +
  theme_stata()

ui_p_mean_per_age_exp52_plot
```
\
\
\

### 2. OLS Analysis

\
$a)$
\
```{r , include=TRUE, message=FALSE}
library(estout)
UI_regression1 = lm(data = UI_RD , formula = durnonemp ~ P)
UI_regression2 = lm(data = UI_RD , formula = durnonemp ~ P + agedays)
UI_regression3 = lm(data = UI_RD , formula = durnonemp ~ P + agedays + edyrs + female + nonger + tenure)
UI_regression4 = lm(data = UI_RD , formula = durnonemp ~ P + agedays + edyrs + female + nonger + tenure + realgdpgrowthf1 + unemp)
```
\
\
Here I use the package $estout$ to export a $\LaTeX$ regression table.
\
I exported the table and included it as an image in this document.
\
```{r}
estclear()
eststo(UI_regression1)
eststo(UI_regression2)
eststo(UI_regression3)
eststo(UI_regression4)
esttab(round.dec = 5 ,filename = "/home/jonas/Documents/Programming/R/Labor Economics [2020]/UI_table")
```
\
```{r , out.width = "500px" , fig.align="center" , echo=FALSE}
knitr::include_graphics("/home/jonas/Documents/Programming/R/Labor Economics [2020]/UI_table/UI_table-1.jpg")
```


\
$b)$
\
Including Age in the regression changes the $\beta_P$ coefficient from positive to negative.
\
An additional month of UI would reduce the unemployement duration by 0.2 month.
This is the opposite of what theory would predict
\
\
$c)$
\
Note that potential UI duration might be related to positive worker characteristics.
Worker who are older and had more employment in the past 7 years (one of the criteria
to be eligible for higher P) might be more employable in general and might have an
easier time finding a job.
\
\
\

### 3. Regression Discontinuity Design

\
\
\
$a)$
\
```{r , fig.align="center" }
uidata_temp = UI_RD %>%
  filter(expbaseline >= 52)


agebins = floor((uidata_temp$agedays - (42*365.25))/15)/(365.25/15)+42

N = rep(1,length(agebins))

uidata_temp_density = uidata_temp %>%
  add_column(agebins,N) %>%
  select(durnonemp,duruib,age,agebins,N) %>%
  group_by(agebins) %>%
  summarise(mean_durnonemp = mean(durnonemp),
            mean_duruib = mean(duruib), 
            mean_age = mean(age) ,
            n = sum(N))


ggplot(data = uidata_temp_density) +
  geom_point(aes(x = agebins, y = n),color = "dodgerblue4") +
  scale_y_continuous(limits = c(400,550)) +
  scale_x_continuous(limits = c(40,49.95),breaks = scales::breaks_pretty(n = 6)) +
  geom_vline(xintercept = c(42,44,49),color = "firebrick4",size = 1) +
  xlab("Age at UI Claim") +
  ylab("Frequency") +
  theme_stata()

```
\
\
\
$b)$
\

```{r , fig.align="center"}

agebins2 = floor((uidata_temp$agedays - (42*365.25))/60)/(365.25/60)+42

uidata_temp_density2 = uidata_temp %>%
  add_column(agebins2,N) %>%
  select(durnonemp,duruib,age,agebins2,N) %>%
  group_by(agebins2) %>%
  summarise(mean_durnonemp = mean(durnonemp),
            mean_duruib = mean(duruib), 
            mean_age = mean(age) ,
            n = sum(N))

ggplot(data = uidata_temp_density2) +
  geom_point(aes(x = agebins2, y = mean_durnonemp),color = "dodgerblue4") +
  geom_vline(xintercept = c(42,44,49),color = "firebrick4",size = 1) +
  scale_x_continuous(limits = c(40,49.73) , breaks = scales::breaks_pretty(n = 6)) +
  xlab("Age at UI Claim") +
  ylab("Unemployment Duration") +
  theme_stata()


```
\
The following figure shows that there is a clear increase in unemployment durations
at the thresholds. This is the main outcome of interest and suggests that potential UI
durations do have a positive effect on unemployment durations. At the 42 cutoff it looks
like the 6 additional months of UI increase unemployment duration by a bit less than a
year.
\
\
\
$c)$
\
```{r}

uidata_temp_density3 = uidata_temp %>%
  add_column(agebins2,N) %>%
  select(durnonemp,duruib,age,expbaseline,edyrs,female,tenure,agebins2,N) %>%
  group_by(agebins2) %>%
  summarise(mean_durnonemp = mean(durnonemp),
            mean_duruib = mean(duruib), 
            mean_age = mean(age),
            mean_expbaseline = mean(expbaseline),
            mean_edyrs = mean(edyrs),
            mean_female = mean(female),
            mean_tenure = mean(tenure),
            n = sum(N))

plot_expbaseline = ggplot(data = uidata_temp_density3) +
  geom_point(aes(x = agebins2, y = mean_expbaseline),color = "dodgerblue4") +
  geom_vline(xintercept = c(42,44,49),color = "firebrick4",size = 1) +
  scale_x_continuous(limits = c(40,49.73) , breaks = scales::breaks_pretty(n = 6)) +
  xlab("Age at UI Claim") +
  ylab("Number of Months worked in previous 7 years") +
  theme_stata()
  

plot_edyrs = ggplot(data = uidata_temp_density3) +
  geom_point(aes(x = agebins2, y = mean_edyrs),color = "dodgerblue4") +
  geom_vline(xintercept = c(42,44,49),color = "firebrick4",size = 1) +
  scale_x_continuous(limits = c(40,49.73) , breaks = scales::breaks_pretty(n = 6)) +
  xlab("Age at UI Claim") +
  ylab("Years of Schooling") +
  theme_stata()

plot_female = ggplot(data = uidata_temp_density3) +
  geom_point(aes(x = agebins2, y = mean_female),color = "dodgerblue4") +
  geom_vline(xintercept = c(42,44,49),color = "firebrick4",size = 1) +
  scale_x_continuous(limits = c(40,49.73) , breaks = scales::breaks_pretty(n = 6)) +
  xlab("Age at UI Claim") +
  ylab("Female") +
  theme_stata()

plot_tenure = ggplot(data = uidata_temp_density3) +
  geom_point(aes(x = agebins2, y = mean_tenure),color = "dodgerblue4") +
  geom_vline(xintercept = c(42,44,49),color = "firebrick4",size = 1) +
  scale_x_continuous(limits = c(40,49.73) , breaks = scales::breaks_pretty(n = 6)) +
  xlab("Age at UI Claim") +
  ylab("Tenure at last Employer") +
  theme_stata()
```
\
```{r  , out.width = "1000"}
grid.arrange(plot_expbaseline,plot_edyrs,ncol = 2)
```

$d)$
\
```{r}
ui_data_age = UI_RD %>%
  filter(age >= 40 & age < 44 & expbaseline >= 52) %>%
  mutate(a0 = agedays-(42*365.25)) %>%
  mutate(RD = as.numeric(age >= 42)) %>%
  mutate(a1 = a0 * RD)

UI_regression5 = lm(data = ui_data_age , formula = durnonemp ~ P + a0 + a1);summary(UI_regression5)


```


